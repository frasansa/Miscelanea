---
title: "Tidymodels"
output: html_document
---


```{r setup, include=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Cargar librerías, funciones y Paths------------------------------------------
w_dir <- file.path( "d:", "Users", "20833717H", "Desktop", "R_Projects")
source(file.path(w_dir, "Opioids", "Scripts", "Funciones_Bases_de_Datos.R"))

```

```{r definir_plot, echo=FALSE, warning=FALSE, message=FALSE}
# definir el estilo de los gráficos--------------------------------------------
theme_set(theme_bw())
tema_azul <- theme_update(
  plot.background = element_rect(fill = "lightblue", colour = NA))

# defnir cero días-------------------------------------------------------------
zero_days = difftime(ymd("2000-01-01"), ymd("2000-01-01"), units = "days")

```

```{r}
# cargar base -----------------------------------------------------------------
library(modeldata)

```

```{r}
data(cells, package = "modeldata")
cells
#> # A tibble: 2,019 x 58
#>   case  class angle_ch_1 area_ch_1 avg_inten_ch_1 avg_inten_ch_2 avg_inten_ch_3
#>   <fct> <fct>      <dbl>     <int>          <dbl>          <dbl>          <dbl>
#> 1 Test  PS        143.         185           15.7           4.95           9.55
#> 2 Train PS        134.         819           31.9         207.            69.9 
#> 3 Train WS        107.         431           28.0         116.            63.9 
#> 4 Train PS         69.2        298           19.5         102.            28.2 
#> 5 Test  PS          2.89       285           24.3         112.            20.5 
#> # … with 2,014 more rows, and 51 more variables: avg_inten_ch_4 <dbl>,
#> #   convex_hull_area_ratio_ch_1 <dbl>, convex_hull_perim_ratio_ch_1 <dbl>,
#> #   diff_inten_density_ch_1 <dbl>, diff_inten_density_ch_3 <dbl>, …

```

```{r}
set.seed(123)
cell_split <- initial_split(cells %>% select(-case), 
                            strata = class)
cell_train <- training(cell_split)
cell_test  <- testing(cell_split)

```

```{r}
tune_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

tune_spec
#> Decision Tree Model Specification (classification)
#> 
#> Main Arguments:
#>   cost_complexity = tune()
#>   tree_depth = tune()
#> 
#> Computational engine: rpart

```

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)

```

```{r}
tree_grid %>% 
  count(tree_depth)
#> # A tibble: 5 x 2
#>   tree_depth     n
#>        <int> <int>
#> 1          1     5
#> 2          4     5
#> 3          8     5
#> 4         11     5
#> 5         15     5

```

```{r}
set.seed(234)
cell_folds <- vfold_cv(cell_train)

```

```{r}
set.seed(345)

tree_wf <- workflow() %>%
  add_model(tune_spec) %>%
  add_formula(class ~ .)

tree_res <- 
  tree_wf %>% 
  tune_grid(
    resamples = cell_folds,
    grid = tree_grid
    )

tree_res
#> # Tuning results
#> # 10-fold cross-validation 
#> # A tibble: 10 x 4
#>    splits             id     .metrics          .notes          
#>    <list>             <chr>  <list>            <list>          
#>  1 <split [1.4K/152]> Fold01 <tibble [50 × 6]> <tibble [0 × 1]>
#>  2 <split [1.4K/152]> Fold02 <tibble [50 × 6]> <tibble [0 × 1]>
#>  3 <split [1.4K/152]> Fold03 <tibble [50 × 6]> <tibble [0 × 1]>
#>  4 <split [1.4K/152]> Fold04 <tibble [50 × 6]> <tibble [0 × 1]>
#>  5 <split [1.4K/152]> Fold05 <tibble [50 × 6]> <tibble [0 × 1]>
#>  6 <split [1.4K/151]> Fold06 <tibble [50 × 6]> <tibble [0 × 1]>
#>  7 <split [1.4K/151]> Fold07 <tibble [50 × 6]> <tibble [0 × 1]>
#>  8 <split [1.4K/151]> Fold08 <tibble [50 × 6]> <tibble [0 × 1]>
#>  9 <split [1.4K/151]> Fold09 <tibble [50 × 6]> <tibble [0 × 1]>
#> 10 <split [1.4K/151]> Fold10 <tibble [50 × 6]> <tibble [0 × 1]>

```

```{r}
tree_res %>% 
  collect_metrics()
#> # A tibble: 50 x 8
#>    cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   
#>              <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>     
#>  1    0.0000000001          1 accuracy binary     0.734    10 0.00877 Preproces…
#>  2    0.0000000001          1 roc_auc  binary     0.772    10 0.00617 Preproces…
#>  3    0.0000000178          1 accuracy binary     0.734    10 0.00877 Preproces…
#>  4    0.0000000178          1 roc_auc  binary     0.772    10 0.00617 Preproces…
#>  5    0.00000316            1 accuracy binary     0.734    10 0.00877 Preproces…
#>  6    0.00000316            1 roc_auc  binary     0.772    10 0.00617 Preproces…
#>  7    0.000562              1 accuracy binary     0.734    10 0.00877 Preproces…
#>  8    0.000562              1 roc_auc  binary     0.772    10 0.00617 Preproces…
#>  9    0.1                   1 accuracy binary     0.734    10 0.00877 Preproces…
#> 10    0.1                   1 roc_auc  binary     0.772    10 0.00617 Preproces…
#> # … with 40 more rows

```

```{r}
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)

```

```{r}
tree_res %>%
  show_best("roc_auc")
#> # A tibble: 5 x 8
#>   cost_complexity tree_depth .metric .estimator  mean     n std_err .config     
#>             <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       
#> 1    0.0000000001          4 roc_auc binary     0.865    10 0.00965 Preprocesso…
#> 2    0.0000000178          4 roc_auc binary     0.865    10 0.00965 Preprocesso…
#> 3    0.00000316            4 roc_auc binary     0.865    10 0.00965 Preprocesso…
#> 4    0.000562              4 roc_auc binary     0.865    10 0.00965 Preprocesso…
#> 5    0.0000000001          8 roc_auc binary     0.859    10 0.0104  Preprocesso…

```

```{r}
best_tree <- tree_res %>%
  select_best("roc_auc")

best_tree
#> # A tibble: 1 x 3
#>   cost_complexity tree_depth .config              
#>             <dbl>      <int> <chr>                
#> 1    0.0000000001          4 Preprocessor1_Model06

```

```{r}
final_wf <- 
  tree_wf %>% 
  finalize_workflow(best_tree)

final_wf
#> ══ Workflow ══════════════════════════════════════════════════════════
#> Preprocessor: Formula
#> Model: decision_tree()
#> 
#> ── Preprocessor ──────────────────────────────────────────────────────
#> class ~ .
#> 
#> ── Model ─────────────────────────────────────────────────────────────
#> Decision Tree Model Specification (classification)
#> 
#> Main Arguments:
#>   cost_complexity = 1e-10
#>   tree_depth = 4
#> 
#> Computational engine: rpart

```

```{r}
final_tree <- 
  final_wf %>%
  fit(data = cell_train) 

final_tree
#> ══ Workflow [trained] ════════════════════════════════════════════════
#> Preprocessor: Formula
#> Model: decision_tree()
#> 
#> ── Preprocessor ──────────────────────────────────────────────────────
#> class ~ .
#> 
#> ── Model ─────────────────────────────────────────────────────────────
#> n= 1515 
#> 
#> node), split, n, loss, yval, (yprob)
#>       * denotes terminal node
#> 
#>  1) root 1515 540 PS (0.64356436 0.35643564)  
#>    2) total_inten_ch_2< 47256.5 731  63 PS (0.91381669 0.08618331)  
#>      4) total_inten_ch_2< 37166 585  19 PS (0.96752137 0.03247863) *
#>      5) total_inten_ch_2>=37166 146  44 PS (0.69863014 0.30136986)  
#>       10) avg_inten_ch_1< 99.15056 98  14 PS (0.85714286 0.14285714) *
#>       11) avg_inten_ch_1>=99.15056 48  18 WS (0.37500000 0.62500000)  
#>         22) fiber_align_2_ch_3>=1.47949 20   8 PS (0.60000000 0.40000000) *
#>         23) fiber_align_2_ch_3< 1.47949 28   6 WS (0.21428571 0.78571429) *
#>    3) total_inten_ch_2>=47256.5 784 307 WS (0.39158163 0.60841837)  
#>      6) fiber_width_ch_1< 11.19756 329 137 PS (0.58358663 0.41641337)  
#>       12) avg_inten_ch_1< 194.4183 254  82 PS (0.67716535 0.32283465) *
#>       13) avg_inten_ch_1>=194.4183 75  20 WS (0.26666667 0.73333333)  
#>         26) total_inten_ch_3>=62458.5 23   9 PS (0.60869565 0.39130435) *
#>         27) total_inten_ch_3< 62458.5 52   6 WS (0.11538462 0.88461538) *
#>      7) fiber_width_ch_1>=11.19756 455 115 WS (0.25274725 0.74725275)  
#>       14) shape_p_2_a_ch_1>=1.225676 300  97 WS (0.32333333 0.67666667)  
#>         28) avg_inten_ch_2>=362.0108 55  23 PS (0.58181818 0.41818182) *
#>         29) avg_inten_ch_2< 362.0108 245  65 WS (0.26530612 0.73469388) *
#>       15) shape_p_2_a_ch_1< 1.225676 155  18 WS (0.11612903 0.88387097) *

```

```{r}
library(vip)

final_tree %>% 
  pull_workflow_fit() %>% 
  vip()

```

```{r}
final_fit <- 
  final_wf %>%
  last_fit(cell_split) 

final_fit %>%
  collect_metrics()
#> # A tibble: 2 x 4
#>   .metric  .estimator .estimate .config             
#>   <chr>    <chr>          <dbl> <chr>               
#> 1 accuracy binary         0.802 Preprocessor1_Model1
#> 2 roc_auc  binary         0.860 Preprocessor1_Model1

final_fit %>%
  collect_predictions() %>% 
  roc_curve(class, .pred_PS) %>% 
  autoplot()

```

```{r}
args(decision_tree)
#> function (mode = "unknown", cost_complexity = NULL, tree_depth = NULL, 
#>     min_n = NULL) 
#> NULL

```

